{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrical RNN\n",
    "### JT Wolohan, Uteerna Koul and Paritosh Prakash\n",
    "\n",
    "**{jwolohan, ukoul, pmorpari}@indiana.edu**\n",
    "\n",
    "*[Copyright (c) 2018 - Mozilla Public License v. 2.0](https://www.mozilla.org/en-US/MPL/2.0/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Imports and data loading\n",
    "We're just bringing in the data we're going to need later and some modules for our data loading steps.\n",
    "The actual modeling is **way** below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import gensim\n",
    "from gensim.models.fasttext import FastText\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import nltk\n",
    "from math import log10\n",
    "import csv\n",
    "import pickle\n",
    "import Lyrics2Vectors as l2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyricVectors = FastText.load(\"LyricVectors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesAndLyrics = l2v.loadTitlesLyrics()\n",
    "lyr_idfs = pickle.load(open(\"LyricTokenIDFs.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lyr2Mat Class\n",
    "This class is the workhorse of our preprocessing efforts. Feed this class with a spacy NLP model, a word vector model, and a dict of IDF scores from the training data and it'll be able to produce input matricies for use in the sequence to sequence RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lyr2Mat:\n",
    "  def __init__(self,nlp,vecs,idfs):\n",
    "    self._nlp = nlp\n",
    "    self._wv = vecs\n",
    "    self._idfs = idfs\n",
    "    self._lyrics_tf = {}\n",
    "  def _cleanLookup(self,tkn):\n",
    "    if tkn in self._wv.vocab.keys():\n",
    "      v = self._wv[tkn]\n",
    "    else:\n",
    "      v = np.zeros(100)\n",
    "    return v   \n",
    "  def vectorize(self,token):\n",
    "    \"\"\"Turns token into wordspace, pos, tf, idf vector\"\"\"\n",
    "    tkn = token.text\n",
    "    pos = np.array(token.pos)\n",
    "    idf = np.array(self._idfs.get(tkn,0))\n",
    "    tf = np.array(log10(1+self._lyrics_tf.get(tkn,0)))\n",
    "    v = self._cleanLookup(tkn)\n",
    "    return np.hstack((v,pos,tf,idf))\n",
    "  def title2Seq(self,title):\n",
    "    \"\"\"Converts a title to a sequence of vectors\"\"\"\n",
    "    return np.array([self._cleanLookup(tkn) for tkn in nltk.tokenize.word_tokenize(title)])\n",
    "  def decodeMatrix(self,M):\n",
    "    return \" \".join([self._wv.similar_by_vector(row,topn=1)[0][0] for row in M])\n",
    "  def creatify(self,words,creative=\"happy\"):\n",
    "    return \" \".join([lyricVectors.wv.most_similar(positive=[word,creative])[0][0] for word in words.split()])\n",
    "  def createInputMatrix(self,lyrics):\n",
    "    \"\"\"Converts lyrics into input matrix\"\"\"\n",
    "    tokens = nltk.tokenize.word_tokenize(lyrics)\n",
    "    self._lyrics_tf = {x:tokens.count(x) for x in set(tokens)}\n",
    "    tokens = self._nlp(lyrics)\n",
    "    return np.array([self.vectorize(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lyr2Mat example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "L2M = Lyr2Mat(_nlp,lyricVectors.wv,lyr_idfs)\n",
    "lyrics = titlesAndLyrics['Lyrics'][:100]\n",
    "title = titlesAndLyrics['Titles'][:100]\n",
    "\n",
    "max_encoder_seq_length = max([len(titlesAndLyrics['Lyrics'][i].split()) for i in range(100)])\n",
    "max_encoder_seq_length = 1000\n",
    "max_decoder_seq_length = max([len(titlesAndLyrics['Titles'][i].split()) for i in range(100)])\n",
    "max_decoder_seq_length = 50\n",
    "\n",
    "print(max_encoder_seq_length)\n",
    "\n",
    "inputs = np.zeros((100,max_encoder_seq_length,103))\n",
    "for i in range(100):\n",
    "    zeros=np.zeros(103)\n",
    "    zeros=zeros.reshape(1,103)\n",
    "    \n",
    "    ones=np.ones(103)\n",
    "    ones=ones.reshape(1,103)\n",
    "\n",
    "    start=zeros\n",
    "\n",
    "    # Appending 0s at start\n",
    "    temp=np.append(start,L2M.createInputMatrix(titlesAndLyrics['Lyrics'][i]),axis=0)\n",
    "\n",
    "    #Appending 1s to end the sequence\n",
    "    temp=np.append(temp,ones,axis=0)\n",
    "\n",
    "    # Standardize the input_size to length 1000\n",
    "\n",
    "    for j in range(len(temp),max_encoder_seq_length):\n",
    "        temp=np.append(temp,zeros,axis=0)\n",
    "    inputs[i]=temp\n",
    "\n",
    "# inputs = [L2M.createInputMatrix(titlesAndLyrics['Lyrics'][i]) for i in range(100)]\n",
    "# inputs=np.asarray(inputs)\n",
    "# inputs.shape\n",
    "\n",
    "# targets = [L2M.title2Seq(titlesAndLyrics['Titles'][i]) for i in range(100)]\n",
    "#pickle.dump(inputs,open(\"ShortInput.pkl\",\"wb\"))\n",
    "#pickle.dump(targets,open(\"ShortOutput.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50, 103)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_decoder_seq_length = 50\n",
    "targets = np.zeros((100,max_decoder_seq_length,103))\n",
    "for i in range(100):\n",
    "    zeros=np.zeros(103)\n",
    "    zeros=zeros.reshape(1,103)\n",
    "    start=zeros\n",
    "    \n",
    "    # Appending 0s at start\n",
    "    temp=np.append(start,L2M.createInputMatrix(titlesAndLyrics['Titles'][i]),axis=0)\n",
    "    \n",
    "    ones=np.ones(103)\n",
    "    ones=ones.reshape(1,103)\n",
    "    #Appending 1s to end the sequence\n",
    "    temp=np.append(temp,ones,axis=0)\n",
    "    \n",
    "    # Standardize the output to length 50 \n",
    "    for j in range(len(temp),max_decoder_seq_length):\n",
    "        temp=np.append(temp,zeros,axis=0)\n",
    "    targets[i]=temp\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-451068ff9872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt_shift_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mt_shift_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "t_shift_target=np.zeros(targets.shape)\n",
    "for t in range[50]:\n",
    "    t_shift_target[:,t+1,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8566208034543834098\n"
     ]
    }
   ],
   "source": [
    "print(_nlp.vocab.strings[\"apple\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've Been Waiting For You\n",
      "I-love-you i've Aberdeen waiting Foreclosure You-you-you\n",
      "'just i've spleen Awaiting Force You'se\n",
      "los i've Eileen longing Foreclosure oiou\n",
      "'happy you've Eileen waiting Unhappy You-you-you\n",
      "afriad i've Eileen longing Forsaken oiou\n"
     ]
    }
   ],
   "source": [
    "t = titlesAndLyrics[\"Titles\"][45]\n",
    "print(t)\n",
    "t = L2M.decodeMatrix(L2M.title2Seq(t))\n",
    "print(L2M.creatify(t,\"love\"))\n",
    "print(L2M.creatify(t,\"lust\"))\n",
    "print(L2M.creatify(t,\"loss\"))\n",
    "print(L2M.creatify(t,\"happy\"))\n",
    "print(L2M.creatify(t,\"sad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Seq2Seq RNN begins here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Below is boilerplate from the Keras\n",
    "### TODO: Change this!\n",
    "### https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense,Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1000, 103)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep the input\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = 200\n",
    "num_decoder_tokens = 10\n",
    "batch_size = len(inputs)\n",
    "num_parameters = 103\n",
    "# max_encoder_seq_length = max([len(titlesAndLyrics['Lyrics'][i].split()) for i in range(100)])\n",
    "# max_decoder_seq_length = max([len(titlesAndLyrics['Titles'][i].split()) for i in range(100)])\n",
    "\n",
    "encoder_inputs = Input(shape=(None, 103))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "decoder_inputs = Input(shape=(None, 103))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(103, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "80/80 [==============================] - ETA: 0s - loss: 7.075 - 2s 27ms/step - loss: 6.9821 - val_loss: 6.4657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e566ea5f8>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.fit([inputs, targets], targets,\n",
    "          batch_size=64,\n",
    "          epochs=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_20 to have 3 dimensions, but got array with shape (1000, 103)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-cd1a9f5ecd08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#inputs[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-154-1492f7df71e1>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Encode the input as state vectors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mstates_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Generate empty target sequence of length 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paritosh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Paritosh\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected input_20 to have 3 dimensions, but got array with shape (1000, 103)"
     ]
    }
   ],
   "source": [
    "#inputs[0]\n",
    "decode_sequence(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
